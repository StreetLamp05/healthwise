{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d30e02f8-5cbd-4e05-93cc-bd3e0bf7f6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from xgboost) (2.0.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from xgboost) (2.21.5)\n",
      "Requirement already satisfied: scipy in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21d5b333-16a9-4dab-a6a0-7821258e1dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      REGION  ILITOTAL  Population  Median_Income       DATE\n",
      "0    Alabama     249.0   5074296.0        59674.0 2010-10-04\n",
      "52   Alabama     239.0   5074296.0        59674.0 2010-10-11\n",
      "104  Alabama     232.0   5074296.0        59674.0 2010-10-18\n",
      "156  Alabama     274.0   5074296.0        59674.0 2010-10-25\n",
      "208  Alabama     342.0   5074296.0        59674.0 2010-11-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load ILI Data (historical weekly flu totals per state)\n",
    "ili_file_path = \"ILINet.csv\"\n",
    "ili_df = pd.read_csv(ili_file_path, na_values=[\"X\"])\n",
    "\n",
    "# Fetch Census Data from API (State-Level Population & Income)\n",
    "census_url = \"https://api.census.gov/data/2022/acs/acs1?get=NAME,B01003_001E,B19013_001E&for=state:*\"\n",
    "census_response = requests.get(census_url)\n",
    "census_data = census_response.json()\n",
    "\n",
    "# Convert to DataFrame\n",
    "columns = [\"State\", \"Population\", \"Median_Income\", \"State_Code\"]\n",
    "df_census = pd.DataFrame(census_data[1:], columns=columns)\n",
    "df_census[\"Population\"] = df_census[\"Population\"].astype(int)\n",
    "df_census[\"Median_Income\"] = df_census[\"Median_Income\"].astype(int)\n",
    "\n",
    "# Merge ILI Data with Census Data\n",
    "df = ili_df.merge(df_census, left_on=\"REGION\", right_on=\"State\", how=\"left\")\n",
    "\n",
    "# Keep relevant columns\n",
    "df = df[[\"REGION\", \"YEAR\", \"WEEK\", \"ILITOTAL\", \"Population\", \"Median_Income\"]]\n",
    "\n",
    "# Convert YEAR & WEEK into DateTime format\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"YEAR\"].astype(str) + \"-\" + df[\"WEEK\"].astype(str) + \"-1\", format=\"%Y-%W-%w\")\n",
    "\n",
    "# Drop YEAR & WEEK\n",
    "df.drop(columns=[\"YEAR\", \"WEEK\"], inplace=True)\n",
    "\n",
    "# Sort by state & date\n",
    "df.sort_values(by=[\"REGION\", \"DATE\"], inplace=True)\n",
    "\n",
    "# Display structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e97ecb2-80a4-4234-a550-f52917e98f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      REGION  ILITOTAL  Population  Median_Income       DATE  ILI_LAG_1  \\\n",
      "208  Alabama     342.0   5074296.0        59674.0 2010-11-01      274.0   \n",
      "260  Alabama     419.0   5074296.0        59674.0 2010-11-08      342.0   \n",
      "312  Alabama     434.0   5074296.0        59674.0 2010-11-15      419.0   \n",
      "364  Alabama     360.0   5074296.0        59674.0 2010-11-22      434.0   \n",
      "416  Alabama     467.0   5074296.0        59674.0 2010-11-29      360.0   \n",
      "\n",
      "     ILI_LAG_2  ILI_LAG_3  ILI_LAG_4  ILI_ROLLING_MEAN  WEEK  \n",
      "208      232.0      239.0      249.0            271.75    44  \n",
      "260      274.0      232.0      239.0            316.75    45  \n",
      "312      342.0      274.0      232.0            367.25    46  \n",
      "364      419.0      342.0      274.0            388.75    47  \n",
      "416      434.0      419.0      342.0            420.00    48  \n"
     ]
    }
   ],
   "source": [
    "# Function to create lag features\n",
    "def create_lagged_features(df, lags=[1, 2, 3, 4]):\n",
    "    for lag in lags:\n",
    "        df[f\"ILI_LAG_{lag}\"] = df.groupby(\"REGION\")[\"ILITOTAL\"].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Function to add rolling averages for trend detection\n",
    "def create_rolling_features(df, window=4):\n",
    "    df[\"ILI_ROLLING_MEAN\"] = df.groupby(\"REGION\")[\"ILITOTAL\"].rolling(window=window).mean().reset_index(level=0, drop=True)\n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "df = create_lagged_features(df)\n",
    "df = create_rolling_features(df)\n",
    "\n",
    "# Encode week of the year as a feature\n",
    "df[\"WEEK\"] = df[\"DATE\"].dt.isocalendar().week\n",
    "\n",
    "\n",
    "# Drop NaN rows from shifting\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Show processed dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ae9f354-5aa0-4e2c-9a90-c939903b142f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define features & target\n",
    "X = df[[\"Population\", \"Median_Income\", \"ILI_LAG_1\", \"ILI_LAG_2\", \"ILI_LAG_3\", \"ILI_LAG_4\", \"ILI_ROLLING_MEAN\", \"WEEK\"]]\n",
    "y = df[\"ILITOTAL\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train XGBoost Model (Using GPU)\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c9d9c0f-5487-446a-a632-c2507407fdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.set_params(device=\"cpu\")  # Force model to run on CPU\n",
    "y_pred = xgb_model.predict(X_test)  # Predict normally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "100653a4-73ed-48da-9591-79adfcff1426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 61.5878\n",
      "Mean Squared Error (MSE): 48984.9085\n",
      "Root Mean Squared Error (RMSE): 221.3253\n",
      "R² Score: 0.9575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate errors\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)  # Root Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)  # R-squared score\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a78f81ec-4f1b-4888-903a-f07ab860c2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (4.2.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: colorlog in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from optuna) (2.0.38)\n",
      "Requirement already satisfied: tqdm in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/hice1/crunch40/.jupyterhub/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3af1c8d3-985a-461b-a71a-605a295a976b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-22 18:21:58,024] A new study created in memory with name: no-name-c8e6e151-380e-4ed9-86f6-596950ead8a5\n",
      "[I 2025-02-22 18:21:58,300] Trial 0 finished with value: 221.52660092967355 and parameters: {'n_estimators': 300, 'learning_rate': 0.1975243962001115, 'max_depth': 5, 'subsample': 0.7414599633034853, 'colsample_bytree': 0.9475459104303356, 'gamma': 1.9885927398938719, 'min_child_weight': 10}. Best is trial 0 with value: 221.52660092967355.\n",
      "[I 2025-02-22 18:21:58,407] Trial 1 finished with value: 244.87972948902828 and parameters: {'n_estimators': 100, 'learning_rate': 0.18500912860333496, 'max_depth': 5, 'subsample': 0.6886403272530262, 'colsample_bytree': 0.6163138675756376, 'gamma': 4.444915833614749, 'min_child_weight': 5}. Best is trial 0 with value: 221.52660092967355.\n",
      "[I 2025-02-22 18:21:58,891] Trial 2 finished with value: 235.9228392271914 and parameters: {'n_estimators': 200, 'learning_rate': 0.10800390757516283, 'max_depth': 10, 'subsample': 0.9705337400252573, 'colsample_bytree': 0.7083411538362164, 'gamma': 3.452465885311555, 'min_child_weight': 8}. Best is trial 0 with value: 221.52660092967355.\n",
      "[I 2025-02-22 18:21:59,624] Trial 3 finished with value: 227.4408749920744 and parameters: {'n_estimators': 500, 'learning_rate': 0.12757305904209132, 'max_depth': 8, 'subsample': 0.8483432842431343, 'colsample_bytree': 0.9463144945817037, 'gamma': 1.337420377874592, 'min_child_weight': 7}. Best is trial 0 with value: 221.52660092967355.\n",
      "[I 2025-02-22 18:22:00,709] Trial 4 finished with value: 223.8422163195608 and parameters: {'n_estimators': 1000, 'learning_rate': 0.05494572491844625, 'max_depth': 6, 'subsample': 0.6097712930236149, 'colsample_bytree': 0.8975678863359486, 'gamma': 1.5322034059086076, 'min_child_weight': 3}. Best is trial 0 with value: 221.52660092967355.\n",
      "[I 2025-02-22 18:22:01,144] Trial 5 finished with value: 230.79999251601222 and parameters: {'n_estimators': 300, 'learning_rate': 0.19994334106432737, 'max_depth': 8, 'subsample': 0.7977667772641804, 'colsample_bytree': 0.8791683820455518, 'gamma': 4.828431169268915, 'min_child_weight': 9}. Best is trial 0 with value: 221.52660092967355.\n",
      "[I 2025-02-22 18:22:01,381] Trial 6 finished with value: 261.9951969022547 and parameters: {'n_estimators': 300, 'learning_rate': 0.014583707145951504, 'max_depth': 4, 'subsample': 0.6617060569039847, 'colsample_bytree': 0.9579834586607918, 'gamma': 2.60982829332735, 'min_child_weight': 3}. Best is trial 0 with value: 221.52660092967355.\n",
      "[I 2025-02-22 18:22:02,330] Trial 7 finished with value: 219.7570169594424 and parameters: {'n_estimators': 800, 'learning_rate': 0.10183559660815653, 'max_depth': 7, 'subsample': 0.639814029168906, 'colsample_bytree': 0.9865546082853838, 'gamma': 3.7095883351261993, 'min_child_weight': 9}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:03,143] Trial 8 finished with value: 226.32712312826456 and parameters: {'n_estimators': 900, 'learning_rate': 0.030962880174012324, 'max_depth': 5, 'subsample': 0.7090643725456091, 'colsample_bytree': 0.6604950352343356, 'gamma': 0.7539241708979916, 'min_child_weight': 3}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:04,196] Trial 9 finished with value: 247.8800475838463 and parameters: {'n_estimators': 900, 'learning_rate': 0.294118606027033, 'max_depth': 7, 'subsample': 0.6614516142754424, 'colsample_bytree': 0.7431966210498406, 'gamma': 1.8078538095722712, 'min_child_weight': 9}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:04,626] Trial 10 finished with value: 238.0627951530944 and parameters: {'n_estimators': 700, 'learning_rate': 0.058650336018328565, 'max_depth': 3, 'subsample': 0.9065700727381671, 'colsample_bytree': 0.8142269434836003, 'gamma': 3.3465710998588287, 'min_child_weight': 6}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:05,363] Trial 11 finished with value: 223.52224749849995 and parameters: {'n_estimators': 600, 'learning_rate': 0.09336689147279081, 'max_depth': 7, 'subsample': 0.7589353237836453, 'colsample_bytree': 0.999657574478198, 'gamma': 2.9026655752475747, 'min_child_weight': 10}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:06,241] Trial 12 finished with value: 237.42062720475784 and parameters: {'n_estimators': 500, 'learning_rate': 0.299165217331931, 'max_depth': 10, 'subsample': 0.7467140300585204, 'colsample_bytree': 0.8553333733171581, 'gamma': 0.13892631419154444, 'min_child_weight': 10}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:07,051] Trial 13 finished with value: 224.23231065585523 and parameters: {'n_estimators': 700, 'learning_rate': 0.028479861716387396, 'max_depth': 6, 'subsample': 0.6245756599955238, 'colsample_bytree': 0.9992872970548908, 'gamma': 4.013588187801926, 'min_child_weight': 1}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:07,526] Trial 14 finished with value: 226.63858973703393 and parameters: {'n_estimators': 300, 'learning_rate': 0.07873477580883487, 'max_depth': 8, 'subsample': 0.8288066604259665, 'colsample_bytree': 0.9320305854868662, 'gamma': 2.1520705966534206, 'min_child_weight': 8}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:08,011] Trial 15 finished with value: 228.5330645723151 and parameters: {'n_estimators': 800, 'learning_rate': 0.16767259537710083, 'max_depth': 3, 'subsample': 0.7437463777276747, 'colsample_bytree': 0.8099781446531641, 'gamma': 3.743607038212252, 'min_child_weight': 10}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:08,393] Trial 16 finished with value: 227.03525596581187 and parameters: {'n_estimators': 400, 'learning_rate': 0.03838922884352907, 'max_depth': 5, 'subsample': 0.6022969581839528, 'colsample_bytree': 0.9138833605561343, 'gamma': 2.8974351891364467, 'min_child_weight': 6}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:08,675] Trial 17 finished with value: 449.7212791126982 and parameters: {'n_estimators': 100, 'learning_rate': 0.010050324425585183, 'max_depth': 9, 'subsample': 0.707202808091722, 'colsample_bytree': 0.7564785162121547, 'gamma': 2.292217644472622, 'min_child_weight': 8}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:09,132] Trial 18 finished with value: 226.35682789046783 and parameters: {'n_estimators': 600, 'learning_rate': 0.13944291585052718, 'max_depth': 4, 'subsample': 0.7895120677611596, 'colsample_bytree': 0.8580582874191379, 'gamma': 1.0697475666584144, 'min_child_weight': 9}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:09,582] Trial 19 finished with value: 227.4679297472336 and parameters: {'n_estimators': 400, 'learning_rate': 0.07974101328099872, 'max_depth': 6, 'subsample': 0.6600821725156318, 'colsample_bytree': 0.9641916615732977, 'gamma': 4.302503482528417, 'min_child_weight': 5}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:10,473] Trial 20 finished with value: 246.83482475042612 and parameters: {'n_estimators': 700, 'learning_rate': 0.2239755540602185, 'max_depth': 7, 'subsample': 0.8699307546335412, 'colsample_bytree': 0.8571747865441232, 'gamma': 3.1556990755368846, 'min_child_weight': 7}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:11,210] Trial 21 finished with value: 222.91858276648006 and parameters: {'n_estimators': 600, 'learning_rate': 0.08810632211036144, 'max_depth': 7, 'subsample': 0.75244211927381, 'colsample_bytree': 0.9957597396075129, 'gamma': 2.897516061608603, 'min_child_weight': 10}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:12,191] Trial 22 finished with value: 223.00846758461665 and parameters: {'n_estimators': 800, 'learning_rate': 0.06920284655541732, 'max_depth': 7, 'subsample': 0.7742864537228454, 'colsample_bytree': 0.9787904561024283, 'gamma': 2.097702996286343, 'min_child_weight': 10}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:13,454] Trial 23 finished with value: 223.71409954794785 and parameters: {'n_estimators': 800, 'learning_rate': 0.1207247743546845, 'max_depth': 9, 'subsample': 0.7250300261674814, 'colsample_bytree': 0.9275379298037364, 'gamma': 2.624040297499408, 'min_child_weight': 9}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:14,096] Trial 24 finished with value: 226.82755099518866 and parameters: {'n_estimators': 600, 'learning_rate': 0.09719129674737824, 'max_depth': 6, 'subsample': 0.813223577560422, 'colsample_bytree': 0.9628200544405391, 'gamma': 3.7027029406941363, 'min_child_weight': 10}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:14,413] Trial 25 finished with value: 231.96896707087782 and parameters: {'n_estimators': 400, 'learning_rate': 0.04591020292303103, 'max_depth': 4, 'subsample': 0.682316757848561, 'colsample_bytree': 0.9983936869621496, 'gamma': 1.815417821297052, 'min_child_weight': 8}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:15,281] Trial 26 finished with value: 223.0126491877862 and parameters: {'n_estimators': 1000, 'learning_rate': 0.14068521329558992, 'max_depth': 5, 'subsample': 0.6335432754752468, 'colsample_bytree': 0.8940148864920551, 'gamma': 4.884552542233988, 'min_child_weight': 9}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:16,031] Trial 27 finished with value: 237.4286820898565 and parameters: {'n_estimators': 500, 'learning_rate': 0.225777439816458, 'max_depth': 8, 'subsample': 0.9038142825909175, 'colsample_bytree': 0.9366742322678173, 'gamma': 3.038386813505577, 'min_child_weight': 7}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:16,386] Trial 28 finished with value: 226.98306995692363 and parameters: {'n_estimators': 200, 'learning_rate': 0.15479224179242743, 'max_depth': 9, 'subsample': 0.7285470268415926, 'colsample_bytree': 0.9786811327823446, 'gamma': 2.4615809985737545, 'min_child_weight': 10}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:17,194] Trial 29 finished with value: 238.7113007323385 and parameters: {'n_estimators': 900, 'learning_rate': 0.17832806235440254, 'max_depth': 5, 'subsample': 0.6989629401588996, 'colsample_bytree': 0.6393527640948724, 'gamma': 4.3430152360723575, 'min_child_weight': 4}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:17,339] Trial 30 finished with value: 236.0044389603388 and parameters: {'n_estimators': 100, 'learning_rate': 0.06741014237859048, 'max_depth': 6, 'subsample': 0.7766342582141346, 'colsample_bytree': 0.9102976758710845, 'gamma': 3.825039349121517, 'min_child_weight': 9}. Best is trial 7 with value: 219.7570169594424.\n",
      "[I 2025-02-22 18:22:18,314] Trial 31 finished with value: 219.3180908396888 and parameters: {'n_estimators': 800, 'learning_rate': 0.07048758295303903, 'max_depth': 7, 'subsample': 0.7670555427988147, 'colsample_bytree': 0.977427256345686, 'gamma': 1.9869368192988328, 'min_child_weight': 10}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:19,190] Trial 32 finished with value: 228.31960484928914 and parameters: {'n_estimators': 700, 'learning_rate': 0.10099783673164683, 'max_depth': 7, 'subsample': 0.832044790382531, 'colsample_bytree': 0.9754989098434843, 'gamma': 1.8603414163161283, 'min_child_weight': 8}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:20,508] Trial 33 finished with value: 223.56821089841262 and parameters: {'n_estimators': 900, 'learning_rate': 0.04421474824385872, 'max_depth': 8, 'subsample': 0.9576650004928362, 'colsample_bytree': 0.9524787984547546, 'gamma': 3.434094817208744, 'min_child_weight': 10}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:21,474] Trial 34 finished with value: 220.01762596244782 and parameters: {'n_estimators': 800, 'learning_rate': 0.11442238167929877, 'max_depth': 7, 'subsample': 0.6821687874754396, 'colsample_bytree': 0.9368249994277856, 'gamma': 1.4692871046123934, 'min_child_weight': 9}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:22,313] Trial 35 finished with value: 224.3242080697403 and parameters: {'n_estimators': 800, 'learning_rate': 0.11362210348415647, 'max_depth': 6, 'subsample': 0.6790919427579026, 'colsample_bytree': 0.8820584076843067, 'gamma': 1.2095047064140163, 'min_child_weight': 8}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:23,265] Trial 36 finished with value: 235.0646818478657 and parameters: {'n_estimators': 800, 'learning_rate': 0.22866225053049352, 'max_depth': 7, 'subsample': 0.638614769986833, 'colsample_bytree': 0.9372307804961675, 'gamma': 0.769217451240158, 'min_child_weight': 9}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:24,673] Trial 37 finished with value: 234.1340542913066 and parameters: {'n_estimators': 1000, 'learning_rate': 0.11949274314149863, 'max_depth': 8, 'subsample': 0.7284835297175086, 'colsample_bytree': 0.9148600342485186, 'gamma': 1.50477986535049, 'min_child_weight': 7}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:24,878] Trial 38 finished with value: 227.68886213987292 and parameters: {'n_estimators': 200, 'learning_rate': 0.06132725797013662, 'max_depth': 5, 'subsample': 0.6503846543308623, 'colsample_bytree': 0.8378838815334795, 'gamma': 0.8428060059555058, 'min_child_weight': 9}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:26,814] Trial 39 finished with value: 250.6491717303071 and parameters: {'n_estimators': 900, 'learning_rate': 0.1914155604830027, 'max_depth': 9, 'subsample': 0.6781273733675821, 'colsample_bytree': 0.6909473898408319, 'gamma': 0.3897307891574031, 'min_child_weight': 1}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:27,561] Trial 40 finished with value: 220.03348465137475 and parameters: {'n_estimators': 700, 'learning_rate': 0.04991522207435411, 'max_depth': 6, 'subsample': 0.696703590755086, 'colsample_bytree': 0.7802251558895268, 'gamma': 1.5439408247110902, 'min_child_weight': 8}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:28,330] Trial 41 finished with value: 228.418860078761 and parameters: {'n_estimators': 700, 'learning_rate': 0.022413421797853703, 'max_depth': 6, 'subsample': 0.6988548180344082, 'colsample_bytree': 0.7776152927185475, 'gamma': 1.5267017362141313, 'min_child_weight': 8}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:29,039] Trial 42 finished with value: 220.70139415424748 and parameters: {'n_estimators': 800, 'learning_rate': 0.0479280249483783, 'max_depth': 5, 'subsample': 0.6197295485389248, 'colsample_bytree': 0.7377200356865062, 'gamma': 1.957592340704089, 'min_child_weight': 9}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:30,032] Trial 43 finished with value: 223.7979810027274 and parameters: {'n_estimators': 800, 'learning_rate': 0.033945413499275275, 'max_depth': 7, 'subsample': 0.6200692889423945, 'colsample_bytree': 0.7212588951033084, 'gamma': 1.3372425964387695, 'min_child_weight': 9}. Best is trial 31 with value: 219.3180908396888.\n",
      "[I 2025-02-22 18:22:30,655] Trial 44 finished with value: 219.3144106497629 and parameters: {'n_estimators': 700, 'learning_rate': 0.04987876393986409, 'max_depth': 5, 'subsample': 0.646385321026968, 'colsample_bytree': 0.7785989366947834, 'gamma': 1.683459508458553, 'min_child_weight': 9}. Best is trial 44 with value: 219.3144106497629.\n",
      "[I 2025-02-22 18:22:31,428] Trial 45 finished with value: 227.25386338594308 and parameters: {'n_estimators': 700, 'learning_rate': 0.023141934861669763, 'max_depth': 6, 'subsample': 0.6469178958234587, 'colsample_bytree': 0.7694231925813504, 'gamma': 1.747864622187763, 'min_child_weight': 6}. Best is trial 44 with value: 219.3144106497629.\n",
      "[I 2025-02-22 18:22:32,525] Trial 46 finished with value: 217.77313888716813 and parameters: {'n_estimators': 900, 'learning_rate': 0.07571297597054956, 'max_depth': 7, 'subsample': 0.6707643820896211, 'colsample_bytree': 0.7918384490584499, 'gamma': 1.618739431660753, 'min_child_weight': 8}. Best is trial 46 with value: 217.77313888716813.\n",
      "[I 2025-02-22 18:22:33,636] Trial 47 finished with value: 222.2953362744289 and parameters: {'n_estimators': 900, 'learning_rate': 0.07350467353644699, 'max_depth': 7, 'subsample': 0.6640193398718087, 'colsample_bytree': 0.8040845656262953, 'gamma': 1.0288405475757103, 'min_child_weight': 7}. Best is trial 46 with value: 217.77313888716813.\n",
      "[I 2025-02-22 18:22:34,859] Trial 48 finished with value: 227.38820934589313 and parameters: {'n_estimators': 900, 'learning_rate': 0.05891693775861016, 'max_depth': 8, 'subsample': 0.606968598118064, 'colsample_bytree': 0.8241505667843765, 'gamma': 2.2697066112419146, 'min_child_weight': 10}. Best is trial 46 with value: 217.77313888716813.\n",
      "[I 2025-02-22 18:22:36,217] Trial 49 finished with value: 222.58459285221463 and parameters: {'n_estimators': 1000, 'learning_rate': 0.09281800372084695, 'max_depth': 8, 'subsample': 0.6713128887342634, 'colsample_bytree': 0.787128604363156, 'gamma': 0.5610493848725032, 'min_child_weight': 9}. Best is trial 46 with value: 217.77313888716813.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 900, 'learning_rate': 0.07571297597054956, 'max_depth': 7, 'subsample': 0.6707643820896211, 'colsample_bytree': 0.7918384490584499, 'gamma': 1.618739431660753, 'min_child_weight': 8}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Define objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters to optimize\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, step=100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"tree_method\": \"hist\",  # Use \"hist\" for faster training\n",
    "        \"device\": \"cuda\"  # Enable GPU acceleration\n",
    "    }\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    # Train model with suggested hyperparameters\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate RMSE (lower is better)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    return rmse  # Optuna will try to minimize this\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50)  # Adjust `n_trials` for longer tuning\n",
    "\n",
    "# Show best hyperparameters\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d01bd4f9-62f6-4852-b90b-e278ae89d655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized model trained & saved!\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Train final model using best hyperparameters\n",
    "xgb_model = xgb.XGBRegressor(**best_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save optimized model\n",
    "xgb_model.save_model(\"ili_xgboost_optimized_optimized.json\")\n",
    "\n",
    "print(\"Optimized model trained & saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30d57a10-6ec7-447a-9518-055469d7c0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Model MAE: 57.2974\n",
      "Optimized Model RMSE: 213.6061\n"
     ]
    }
   ],
   "source": [
    "# Predict using the optimized model\n",
    "y_pred_opt = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mae = mean_absolute_error(y_test, y_pred_opt)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_opt))\n",
    "\n",
    "print(f\"Optimized Model MAE: {mae:.4f}\")\n",
    "print(f\"Optimized Model RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6d219-eacf-474b-b544-d08f53f9050c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
